# Databricks Apps + AI Agents Template

A complete template for building and deploying AI agents with **Databricks Apps**. This repo demonstrates best practices for agent development with **MLflow 3.0 monitoring**, **traced function observability**, and a modern chat interface.

üéØ **Perfect for getting started with:**

- **Databricks Agent development** with production monitoring
- **MLflow 3.0 tracing** and experiment tracking
- **Databricks Apps deployment** with a beautiful UI
- **Modern development workflow** with hot reload and automated scripts

‚ú® **What makes this template special:**

- **Ready-to-deploy agent** with chat interface in under 5 minutes
- **Professional dev setup** with automated scripts for development and deployment
- **Production-ready observability** with MLflow tracing and monitoring
- **Optimized dependencies** - lean production builds with conflict-free package management
- **Claude memory ready** - includes [CLAUDE.md](./CLAUDE.md) for AI-assisted development with full project context

<img width="1723" alt="image" src="https://github.com/user-attachments/assets/14aa98ad-33fa-4270-9479-48894dc6f69f" />

The Agent being served:

**databricks_assistant.py** is a LangChain tool-calling agent that can explore and query your Databricks Unity Catalog structure. The agent includes the following tools:

- **list_catalogs**: Lists all available catalogs in the workspace
- **list_schemas**: Lists all schemas in a specific catalog
- **list_tables**: Lists all tables in a specific schema
- **list_volumes**: Lists all volumes in a specific schema

```python
@mlflow.trace(span_type='LLM')
def databricks_agent(messages):
  """A LangChain agent that can explore Databricks catalogs and answer questions."""
  # Initialize ChatDatabricks LLM
  llm = ChatDatabricks(
    endpoint='databricks-claude-sonnet-4',
    max_tokens=1000,
    temperature=0.1,
  )

  # Create catalog exploration tools
  tools = create_catalog_tools()  # list_catalogs, list_schemas, list_tables, list_volumes

  # Create tool-calling agent with custom prompt
  agent = create_tool_calling_agent(llm=llm, tools=tools, prompt=prompt)

  # Execute agent with AgentExecutor for tool orchestration
  agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)
  result = agent_executor.invoke({'input': user_query})

  return formatted_response  # Formatted for UI compatibility
```

The agent uses the Databricks SDK (`WorkspaceClient`) to interact with Unity Catalog, providing dynamic exploration of your data assets. The UI renders markdown responses with proper formatting for lists, code blocks, and emphasis.

## Tech Stack

**üñ•Ô∏è Frontend (Port 3000)**

- **[React](https://react.dev/)** + **[TypeScript](https://www.typescriptlang.org/)** for the UI framework
- **[Vite](https://vitejs.dev/)** for fast development and hot module replacement
- **[shadcn/ui](https://ui.shadcn.com/)** for beautiful, accessible components built on Radix UI
- **[Tailwind CSS](https://tailwindcss.com/)** for styling
- **[Bun](https://bun.sh/)** as the package manager and dev server
- **[react-markdown](https://github.com/remarkjs/react-markdown)** + **[remark-gfm](https://github.com/remarkjs/remark-gfm)** for rendering agent markdown responses

**‚öôÔ∏è Backend (Port 8000)**

- **[FastAPI](https://fastapi.tiangolo.com/)** for the Python API server with auto-docs
- **[uvicorn](https://www.uvicorn.org/)** with hot reload for development
- **[LangChain](https://python.langchain.com/)** for building the tool-calling agent with AgentExecutor
- **[Databricks SDK](https://databricks-sdk-py.readthedocs.io/)** for Unity Catalog operations
- **[OpenAI Python SDK](https://github.com/openai/openai-python)** for Databricks model serving endpoints

**üìä Observability & Deployment**

- **[MLflow](https://mlflow.org/)** for experiment tracking and [agent monitoring/evaluation](https://docs.databricks.com/aws/en/mlflow3/genai/eval-monitor/)
- **[Databricks Apps](https://www.databricks.com/product/databricks-apps)** for production deployment

**üîß Development Tools**

- **Fast edit-refresh cycle**: `./watch.sh` runs both servers with hot reload
- **Frontend proxy**: In dev mode, port 8000 proxies non-API requests to port 3000
- **Auto-reloading**: Backend reloads on Python changes, frontend on React/CSS changes

### Adding UI Components

The template uses **shadcn/ui** for consistent, accessible components:

```bash
# Add a new component (run from project root)
bunx --bun shadcn@latest add button
bunx --bun shadcn@latest add dialog
bunx --bun shadcn@latest add form

# Browse available components
bunx --bun shadcn@latest add
```

Components are installed to `client/src/components/ui/` and use the canonical "@/" import pattern:

```tsx
import { Button } from "@/components/ui/button";
import { Dialog } from "@/components/ui/dialog";
import { Card, CardContent, CardHeader } from "@/components/ui/card";

function MyComponent() {
  return (
    <Card>
      <CardHeader>My Card</CardHeader>
      <CardContent>
        <Button variant="outline">Click me</Button>
      </CardContent>
    </Card>
  );
}
```

**Styling approach:**

- shadcn/ui components use **CSS variables** for theming (see `client/src/index.css`)
- **Tailwind classes** for custom styling and layout
- **Responsive design** built-in with Tailwind's breakpoint system

## Quick Start

Get the template running in 3 commands:

```bash
git clone <this-repo>
./setup.sh                 # Interactive environment setup
./watch.sh                 # Start development server
```

üéâ **Open http://localhost:8000** - You'll have a working chat interface with Databricks agent!

**What you get:**

- ü§ñ Chat interface with AI agent responses (~5-10s response time)
- üìä MLflow experiment tracking with trace IDs
- üî• Hot reload for both frontend and backend changes
- üß™ Built-in testing and formatting tools

## Project Structure

```
‚îú‚îÄ‚îÄ server/                 # FastAPI backend
‚îÇ   ‚îú‚îÄ‚îÄ agents/            # Agent implementations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ databricks_assistant.py  # Main agent (customize this!)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ model_serving.py         # Direct model endpoint calls
‚îÇ   ‚îú‚îÄ‚îÄ app.py             # FastAPI routes and setup
‚îÇ   ‚îî‚îÄ‚îÄ tracing.py         # MLflow integration
‚îú‚îÄ‚îÄ client/                # React frontend
‚îÇ   ‚îú‚îÄ‚îÄ src/components/    # UI components (shadcn/ui based)
‚îÇ   ‚îú‚îÄ‚îÄ src/queries/       # API client and React Query hooks
‚îÇ   ‚îî‚îÄ‚îÄ build/             # Production build output
‚îú‚îÄ‚îÄ scripts/               # Build and utility scripts
‚îú‚îÄ‚îÄ *.sh                   # Development automation scripts
‚îî‚îÄ‚îÄ .env.local            # Environment configuration (create with ./setup.sh)
```

## Customization Guide

**To adapt this template for your use case:**

1. **Change the agent behavior** - Edit `server/agents/databricks_assistant.py`:

   - Modify the `SYSTEM_PROMPT` for your domain
   - Swap the model endpoint (currently Claude Sonnet 4)
   - Add custom logic, retrieval, or tools

2. **Update branding** - Modify `client/src/App.tsx`:

   - Change app title, colors, and styling
   - Add your organization's UI components

3. **Add new endpoints** - Extend `server/app.py`:

   - Follow the existing `/api/agent` pattern
   - Use MLflow tracing for observability

4. **Environment variables** - Update `.env.local`:
   - Point to your Databricks workspace
   - Configure your model serving endpoints
   - Set up your MLflow experiment

# Deploy

## Prerequisites

Make sure you've created a Custom Lakehouse App and you've set the `DATABRICKS_APP_NAME` to the name of the lakehouse app with environment flags above.

## Deploy to LHA

```bash
./deploy.sh
```

**‚ú® Smart deployment verification**: When using Claude Code, simply ask to "deploy" and it will:

- Run the deployment script automatically
- Verify deployment success by checking app status
- Scan logs for errors and provide troubleshooting steps
- Report back with monitoring and access information

Note: you may have to upgrade the databricks CLI for the above command to work.

## Host App Integration

The Agent Monitoring App can be integrated into other React applications (e.g., `dbdemos-genai`) as a compiled, standalone component with **runtime configuration**.

### Quick Integration

```bash
# Build for integration
./scripts/prepare_for_host.sh /path/to/host-app/public/agent-monitoring

# The script will:
# - Build the React frontend with optimized settings
# - Copy all artifacts to the specified directory
# - Create app_config.json template for endpoint configuration
# - Generate detailed integration instructions
```

### Key Features

**üîÑ Runtime Configuration**
- Endpoints loaded from `app_config.json` at runtime
- No rebuild needed to add/remove endpoints
- Host app can generate config dynamically

**üì¶ Self-Contained**
- Compiled to static HTML/JS/CSS
- No dependencies on host app's React version
- Code-split for optimal loading

**üé® Flexible Deployment**
- Static file serving
- Dynamic route integration
- Environment-specific configuration

### Configuration Example

Create `app_config.json` in the deployment directory:

```json
{
  "endpoints": [
    {
      "displayName": "My Agent",
      "endpointName": "ka-6a76cd22-endpoint",
      "type": "databricks-agent"
    },
    {
      "displayName": "Claude Sonnet 4",
      "endpointName": "databricks-claude-sonnet-4",
      "type": "openai-chat"
    }
  ],
  "apiBaseUrl": "/api"
}
```

The app supports two endpoint types:
- **`databricks-agent`**: For Databricks Agent endpoints (uses `input` field format)
- **`openai-chat`**: For OpenAI-compatible endpoints (standard chat format)

### For Complete Integration Guide

See [DEPLOYMENT.md](./DEPLOYMENT.md) for:
- Detailed integration patterns
- Dynamic configuration generation
- Backend API requirements
- Testing strategies
- Troubleshooting guide

## Development

### Prerequisites

```
brew install uv bun
```

### Environment setup

**Option 1: Interactive setup (recommended)**

Run the interactive setup script to create your `.env.local` file:

```bash
./setup.sh
```

**Option 2: Manual setup**

Copy the template and fill in your values:

```bash
cp env.template .env.local
# Edit .env.local with your values
```

**Option 3: Environment variables**

The app automatically falls back to environment variables if `.env.local` is not present:

```bash
export DATABRICKS_HOST="your-workspace.cloud.databricks.com"
export DATABRICKS_TOKEN="dapi..."
export MLFLOW_EXPERIMENT_ID="1234567890"
# Run the app - it will use these environment variables
./watch.sh
```

**Required variables:**

- `DATABRICKS_HOST` - Your Databricks workspace URL
- `DATABRICKS_TOKEN` - Personal Access Token (PAT)
- `MLFLOW_EXPERIMENT_ID` - MLflow experiment for tracing

**For deployment:**

- `DATABRICKS_APP_NAME` - Name of your Databricks App
- `LHA_SOURCE_CODE_PATH` - Workspace path to source code

See `env.template` for all available configuration options.

### Development scripts

**Setup and configuration:**

- `./setup.sh` - Interactive setup to create `.env.local` file
- `./fix.sh` - Format all code (ruff for Python, prettier for TypeScript)
- `./check.sh` - Run code quality checks

**Development and testing:**

- `./watch.sh` - Run fast-edit refresh python + typescript locally
- `./start_prod.sh` - Run the production server locally
- `./test_agent.sh` - Test agent directly without starting full web app

## Claude Code Integration

ü§ñ **This repository is Claude memory ready!**

This project includes comprehensive configuration for [Claude Code](https://docs.anthropic.com/en/docs/claude-code) to accelerate your development workflow. The [CLAUDE.md](./CLAUDE.md) file contains detailed project instructions, conventions, and context that Claude Code uses to understand your codebase and assist effectively.

**What makes this Claude-ready:**

- **Project memory**: [CLAUDE.md](./CLAUDE.md) provides Claude with deep context about the codebase structure, development patterns, and best practices
- **Smart commands**: Claude understands common tasks like "deploy", "test agent", and "fix" without detailed explanations
- **Contextual awareness**: Claude knows about the tech stack, file organization, and project-specific conventions
- **Automated workflows**: Claude can handle complex tasks like deployment verification and dependency conflict resolution

**Key Claude commands:**

- "setup" - Run the interactive environment setup script
- "deploy" - Deploy the application and verify success automatically
- "fix" - Format all code according to project style guidelines
- "test agent" - Test the agent directly without starting the full web application
- "start server" - Run the development server in a screen session
- "kill server" - Stop the development server

Claude Code understands the project structure and can help with development tasks while following the established patterns and conventions. When you work with Claude on this project, it already knows your tooling, dependencies, and workflows!

## Troubleshooting

### Common Issues

**‚ùå "Profile error" when running `./watch.sh`**

- **Solution**: The script handles optional `DATABRICKS_CONFIG_PROFILE` - if not set, it uses default auth
- **Check**: Ensure your `.env.local` has valid `DATABRICKS_HOST` and `DATABRICKS_TOKEN`

**‚ùå Port 8000 already in use**

- **Check**: `lsof -i :8000` to see what's using the port
- **Solution**: Kill the process or change `UVICORN_PORT` in your environment

**‚ùå Frontend not loading/502 errors**

- **Check**: Both uvicorn (backend) and bun (frontend) processes are running
- **Solution**: Run `./watch.sh` again - it starts both servers

**‚ùå Agent responses are slow (>30s)**

- **Expected**: 5-10s response time is normal for LLM calls
- **Check**: Your `DATABRICKS_HOST` network connectivity
- **Monitor**: Use the MLflow experiment link to see trace details

**‚ùå MLflow tracing not working**

- **Check**: `MLFLOW_EXPERIMENT_ID` is set in `.env.local`
- **Verify**: Visit the tracing experiment URL from `/api/tracing_experiment`

### Development Tips

- **Hot reload issues**: If changes aren't picked up, restart `./watch.sh`
- **Screen session stuck**: Use `screen -list` and `screen -X -S lha-dev quit` to force-kill
- **API testing**: Use the built-in curl commands from [CLAUDE.md](./CLAUDE.md)
- **Debug mode**: Add `print()` statements in Python code - they'll show in the uvicorn output

## Contributing to Template

Found a bug or want to improve the template?

1. **Test your changes** with `./test_agent.sh` and `./fix.sh`
2. **Update documentation** if you add new features
3. **Follow the development patterns** established in [CLAUDE.md](./CLAUDE.md)

## License Attribution

This project uses the following open source libraries:

| library           | description           | license    | source                                          |
| ----------------- | --------------------- | ---------- | ----------------------------------------------- |
| FastAPI           | Web framework         | MIT        | https://github.com/tiangolo/fastapi             |
| MLflow            | ML lifecycle platform | Apache 2.0 | https://github.com/mlflow/mlflow                |
| React             | UI framework          | MIT        | https://github.com/facebook/react               |
| TypeScript        | JavaScript superset   | Apache 2.0 | https://github.com/microsoft/TypeScript         |
| Vite              | Build tool            | MIT        | https://github.com/vitejs/vite                  |
| Tailwind CSS      | CSS framework         | MIT        | https://github.com/tailwindlabs/tailwindcss     |
| Radix UI          | UI primitives         | MIT        | https://github.com/radix-ui/primitives          |
| Lucide React      | Icon library          | ISC        | https://github.com/lucide-icons/lucide          |
| OpenAI Python SDK | OpenAI API client     | MIT        | https://github.com/openai/openai-python         |
| Uvicorn           | ASGI server           | BSD        | https://github.com/encode/uvicorn               |
| Pydantic          | Data validation       | MIT        | https://github.com/pydantic/pydantic            |
| Python-dotenv     | Environment variables | BSD        | https://github.com/theskumar/python-dotenv      |
| Databricks SDK    | Databricks API client | Apache 2.0 | https://github.com/databricks/databricks-sdk-py |
| Ruff              | Python linter         | MIT        | https://github.com/astral-sh/ruff               |
| Bun               | JavaScript runtime    | MIT        | https://github.com/oven-sh/bun                  |
