# Project Memory

## Package Management

- Use `uv` for Python package management instead of `pip` directly
- This project uses uv for dependency management and virtual environment handling
- When changing Python dependencies, always use `uv add` or `uv remove` commands instead of editing pyproject.toml directly

## Frontend Setup

- **Always use Bun for frontend operations** - faster than npm/yarn and eliminates dependency conflicts
- Client uses shadcn/ui components with proper TypeScript configuration
- Development: `bun start` or `bun dev` in the client directory
- Build process: `bun run build` in the client directory
- Package management: Use `bun add` and `bun remove` instead of npm
- shadcn components can be added with: `npx shadcn@latest add <component-name>`
- **TypeScript path aliases**: Use canonical `@/` imports (e.g., `import { Button } from "@/components/ui/button"`)
- **Build system**: Vite and TypeScript are configured for "@/" alias support automatically

## Development Server Management

- Use "start server" command to run the development server using `./watch.sh` in a detached screen session
- The dev server runs both the FastAPI backend (port 8000) and React frontend (Vite dev server) with hot reload
- Server status can be checked with "server status" or "is server running" commands
- Server can be stopped with "stop server" or "kill server" commands
- Screen session is named "lha-dev" and can be accessed directly with `screen -r lha-dev`
- When server is running, you can test changes immediately without manual restarts
- The server automatically opens http://localhost:8000 when started

## API Endpoint Testing Methodology

When adding or testing endpoints, use this workflow:

1. **Test the endpoint** with curl:
   ```bash
   curl -X POST http://localhost:8000/api/agent \
     -H "Content-Type: application/json" \
     -d '{"inputs": {"messages": [{"role": "user", "content": "What is Databricks?"}]}}'
   ```
2. **Check server logs** immediately after:
   ```bash
   screen -S lha-dev -X hardcopy /tmp/server_logs.txt && tail -30 /tmp/server_logs.txt
   ```
3. **Verify response** includes expected fields (response, trace_id for agent endpoint)
4. **Confirm MLflow tracing** is working (trace_id should be present)

## Hot Reload Development Workflow

The development server supports real-time code changes:

1. **Add debug prints** to server code (e.g., `print(f"ðŸ”¥ ENDPOINT HIT: {data}")`)
2. **uvicorn auto-reloads** the server when Python files change
3. **Test immediately** with curl - no manual restart needed
4. **Verify functionality** through response content and status codes
5. **Clean up debug code** when done testing
   Note: Screen capture may not always show real-time output clearly, but process monitoring and endpoint testing provide reliable verification.

## Development Server Troubleshooting

- **Profile errors in watch.sh**: The script handles optional DATABRICKS_CONFIG_PROFILE - if not set, uses default auth
- **Screen output capture**: Use `ps aux | grep uvicorn` and direct endpoint testing rather than relying solely on screen hardcopy
- **Port conflicts**: Check `lsof -i :8000` to verify server is listening correctly
- **Process verification**: Multiple uvicorn processes are normal (parent/child from --reload mode)

## Testing

- When making changes to the agent code in `server/agents/databricks_assistant.py`, use `./test_agent.sh` (or `uv run python test_agent.py`) to test the agent directly without starting the full web application
- This executes the actual databricks_assistant.py code and allows for faster iteration and debugging of agent behavior
- The test script shows both the full JSON response and just the content for easier reading
- For full UI testing, use the development server (see Development Server Management section)

## Setup & Environment Configuration

- **Three ways to configure the app:**
  1. **Interactive setup**: Run `./setup.sh` to create/configure .env.local file
  2. **Manual setup**: Copy `env.template` to `.env.local` and fill in values
  3. **Environment variables**: The app automatically falls back to system environment variables if no .env.local file exists
- **Required variables**: DATABRICKS_HOST, DATABRICKS_TOKEN, MLFLOW_EXPERIMENT_ID
- **For deployment**: Also need DATABRICKS_APP_NAME and LHA_SOURCE_CODE_PATH
- See `env.template` for complete documentation of all configuration options

## Code Formatting

- Use `./fix.sh` to format all code according to the project's style guidelines
- This runs ruff formatting/linting for Python files and prettier for TypeScript/JavaScript files
- Run this before committing code to ensure consistent formatting

## Build System & Generated Files

- **Never commit build artifacts**: `client/build/` contains Vite build output (ignored in .gitignore)
- **API client is auto-generated**: `client/src/fastapi_client/` is generated from OpenAPI spec via `uv run python -m scripts.make_fastapi_client`
- **Lock files**: `uv.lock` should be committed to ensure reproducible dependency versions across all developers
- **Development workflow**: The `./watch.sh` script automatically regenerates the API client when backend changes
- When adding new FastAPI endpoints, the TypeScript client updates automatically

## Git Operations

- Use `git pp` instead of `git push` for pushing changes

## Deployment

- When the user says "deploy", use `./deploy.sh` command
- **Automated app.yaml configuration**: Deploy script automatically updates `app.yaml` with `MLFLOW_EXPERIMENT_ID` from `.env.local`
- **Automated verification**: After running deploy.sh, programmatically check deployment success by:
  1. Running `databricks apps list` to verify app appears
  2. Scanning deploy.sh output for success/failure indicators
  3. Checking app status and providing troubleshooting if needed
  4. Reporting deployment status back to user with specific details
- **Authentication in Production**: Databricks Apps use OAuth with `DATABRICKS_CLIENT_ID` and `DATABRICKS_CLIENT_SECRET` instead of token-based auth
  - The code automatically detects and uses OAuth credentials when available
  - Falls back to token-based auth for local development
  - WorkspaceClient() handles auth chain automatically in production

## Production Monitoring

- **App URL Pattern**: After deployment, apps are accessible at `https://{app-name}-{deployment-id}.{region}.databricksapps.com`
- **Key Monitoring Endpoints**:
  1. **App Logs**: `{app-url}/logz` - Real-time application logs (requires browser authentication)
  2. **Health Check**: `{app-url}/api/health` - Quick health status check
  3. **MLflow Experiment**: Check the experiment ID in deployment output for agent traces
- **Post-Deployment Verification**:
  1. Test chat interface with "list catalogs" to verify LangChain agent
  2. Check markdown rendering displays correctly
  3. Verify thumbs up/down feedback functionality works
  4. Monitor MLflow experiment for new traces with each agent interaction
- **Monitoring Best Practices**:
  - Always check deployment output for MLflow experiment ID
  - Use `/api/tracing_experiment` endpoint to get experiment link
  - Monitor logs during first few user interactions
  - Check for any dependency warnings in deployment output

## Host App Integration

The app can be integrated into other React applications (e.g., `dbdemos-genai`) as a compiled standalone component with runtime configuration.

### Integration Branch
- **Branch**: `dbdemos_genai_integration` - dedicated branch for host app integration work
- Contains all changes for runtime configuration and deployment script

### Key Components

1. **Runtime Configuration** (`client/src/config.ts`)
   - Loads `app_config.json` at runtime
   - Falls back to default config in development
   - Allows host app to dynamically configure endpoints

2. **Dynamic Endpoints** (`client/src/endpoints.ts`)
   - Exports `getEndpoints()` function instead of static array
   - Reads endpoints from loaded configuration
   - Supports two endpoint types:
     - `databricks-agent`: Agent endpoints using `input` field format
     - `openai-chat`: OpenAI-compatible chat endpoints

3. **Build Configuration** (`client/vite.config.ts`)
   - Base path set to `./` for flexible deployment
   - Code splitting for vendor libraries
   - Sourcemaps enabled for production debugging

4. **Deployment Script** (`scripts/prepare_for_host.sh`)
   - Builds the React frontend
   - Copies artifacts to specified output directory
   - Creates `app_config.json.template`
   - Generates integration guide

### Usage

```bash
# Build for host integration
./scripts/prepare_for_host.sh /path/to/host-app/public/agent-monitoring

# Creates:
# - Compiled app in specified directory
# - app_config.json.template for endpoint configuration
# - INTEGRATION_GUIDE.md with detailed instructions
```

### Configuration Format

The host app should provide `app_config.json` in the deployment directory:

```json
{
  "endpoints": [
    {
      "displayName": "Agent Name",
      "endpointName": "endpoint-id",
      "type": "databricks-agent"
    }
  ],
  "apiBaseUrl": "/api"
}
```

### API Requirements

The host app must provide these backend endpoints:
- `POST /api/invoke_endpoint` - Invoke agent/model endpoint
- `GET /api/tracing_experiment` - Get MLflow experiment info
- `POST /api/log_feedback` - Log user feedback

### Development vs Deployment

- **Local dev**: Uses hardcoded defaults from `config.ts`
- **Deployed**: Loads config from `app_config.json` at runtime
- **Backward compatible**: Still works as standalone app

### Documentation

- See `DEPLOYMENT.md` for complete integration guide
- Includes patterns for static and dynamic configuration
- Backend API specifications
- Troubleshooting guide

## Reading Databricks Apps Logs

- **Log Access Method**: Databricks Apps logs require OAuth authentication and are accessible through:
  1. Web UI: `https://{app-url}/logz` (requires browser authentication)
  2. WebSocket stream: `wss://{app-url}/logz/stream` (requires authenticated session)
- **Authentication**: Apps use OAuth2 flow redirecting to Databricks workspace for authentication
- **Error Detection Strategy**: Since programmatic log access requires auth, use deployment output and app status:
  1. Check `databricks apps list` for app status (ACTIVE/FAILED)
  2. Monitor deploy.sh output for "Error installing requirements" messages
  3. Use app HTTP response codes (302 = running, 500 = error)
- **Dependency Conflict Resolution**: When pip dependency conflicts occur (e.g., "but you have xyz version"), pin the conflicting packages in pyproject.toml to the exact versions that are already installed in Databricks Apps
- **Common Conflicts**: Packages like tenacity, pillow, websockets, pyarrow, markupsafe, werkzeug, and flask often conflict with pre-installed versions
- **Python Version Requirements**: If databricks-connect version conflicts occur, ensure the requires-python version in pyproject.toml matches the requirements (e.g., databricks-connect==16.2.0 requires Python>=3.12)

## Viewing the UI with Playwright

To view and interact with the development UI:

1. Ensure the dev server is running: `./dev.sh`
2. Use Playwright MCP tools:
   - Navigate: `mcp__playwright__browser_navigate` to `http://localhost:5433`
   - Screenshot: `mcp__playwright__browser_take_screenshot`
   - View DOM: `mcp__playwright__browser_snapshot` to see the accessibility tree and query elements
   - Network: `mcp__playwright__browser_network_requests` to see all network requests
   - Interact: `mcp__playwright__browser_click`, `mcp__playwright__browser_type`, etc.
   - Debug: `mcp__playwright__browser_console_messages` to see console errors
